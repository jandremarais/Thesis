# Experiments and Results \label{chp:results}

\chapterprecishere{"For us, the most important part of rigor is better empiricism, not more mathematical theories."\par\raggedleft--- \textup{Ali Rahimi and Ben Recht}, NIPS 2017}

## Introduction



+ what am I going to do with SRN?

## General Methodology \label{sec:meth}

Unless explicitly stated otherwise, the general experimental methodology will be as follows. Consider the hypothetical case where we want to compare Approach A with Approach B:

+ Evaluate Approach A and Approach B on both the Satellite Images and Chest X-Rays datasets. These datasets are vastly different in terms of the nature of the images and the size of the datasets. However they have roughly the same number of possible labels and therefore our conclusions cannot be assumed to hold for task where $K$ is much larger.
+ For each dataset, evaluate the approaches with 5-fold cross-validation and report each evaluation metric as the average over the 5-folds along with its standard deviation. No other results in the literature are reported in this rigorous way.
+ Compare approaches in terms of the following metrics:

    - label-based macro $F_{1}$-score ($F_{1}^{\text{macro}}$)
    - label-based micro $F_{1}$-score ($F_{1}^{\text{micro}}$)
    - example-based $F_{1}$-score ($F_{1}^{\text{exam}}$)
    - example-based average precision (AP). 
    
    These are chosen since they are the most popular metrics for multi-label image classification in the literature.
+ Report the time taken for each approach to complete training where relevant. This measure is neglected in the literature but is an important factor, especially for use cases where resources are limited.
+ When transfer learning is used, the same preprocessing of the images are done as was for in the training of the original network being transferred from.
+ If no thresholding function is mentioned, then you may assume that a threshold of 0.5 for all labels was used.

## Loss Functions for Multi-Label Image Classification



For comparing the above mentioned loss functions, we will follow a transfer learning like approach. We will use a ResNet-50 pretrained on ImageNet to extract features for each image (of size $224\times 224$), where the features we choose to extract is in the last layer before the classification layer of the ResNet. Thus we will get a 2048-dimensional vector for each image. The only training we will do is of a fully connected layer connecting the 2048-dimensional input to a $K$-dimensional output which is then passed through a sigmoid activation function (Revise number of layers during experiments). This network will be trained using SGD with an initial learning rate of 0.1 which is reduced by a factor of 10 when the loss plateaus. For each loss function we will only run 50 epochs. The rest of the details follow as in \Cref{sec:meth}. Although, we will not look at the precision and recall, because they are summarised by the $F_{1}$-scores.

### Results and Discussion

## Multi-Level Predictions to Detect Small Objects

### Method

### Results

### Discussion

## Exploiting Label Correlations

### Method

### Results

### Discussion

## Label Calibration

### Method

### Results

### Discussion

## The Final Model

### Method

### Results

### Discussion


## Notes

+ maybe also shrink images for faster computations.
+ add time taken for learning as a metric.