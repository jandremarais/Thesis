# Results (/Application)
\label{chp:results}

## Introduction

Main aim is to compare methods on more datasets and in terms of more evaluation metrics. The datasets to be evaluated on are described in Appendix \ref{app:data}. These are the most popular and most recent multi-labelled image datasets.

+ mention the importance of evaluating on multiple ml datasets with different properties.
+ mention the importance of comparing in terms of many evaluation metrics. Which am I going to use here? Probably one of each, example-based, label-based (micro and macro).

Where possible, the basic framework will be to extract features from input images with pretrained (on ImageNet) CNN. The proposals in the literature will be built on top of these features (see transfer learning in Chapter \ref{chp:dnn}). This will not give the best results because these features are trained for single label images. However, they are sufficient for comparison purposes and are much less time consuming. (Maybe I can indentify the most promosing method and see what effect fine-tuning convolutional layers will have on it. This will also allow other bells and whistles such as data augmentation.) The architecture chosen to do the feature extraction is VGG16 because of its simplicity and proven effectiveness in transfer learning. 

+ maybe also shrink images for faster computations.
+ add time taken for learning as a metric.
+ 5- or 10-fold cross-validation for more accurate errors and standard deviations.
+ baseline: sigmoid classification layer optimising binary cross-entropy

## Optimising Multi-Label Loss Functions

+ see the effect of optimising ML loss functions on different metrics.

## Label Embedding Approaches

+ evaluate the effect of label embedding approaches
+ does it help with class imbalance?

## Novel Architectures

+ evaluate the following classification heads:
+ spatial regulrisation network
+ cnn-rnn and improved version
+ Hypothesis CNN Pooling
+ Context gating
+ Chaining
+ Label Processing layers

## Discussion

+ is there a 'best' method?
+ are there any patterns?
+ do they perform as reported by original papers?
