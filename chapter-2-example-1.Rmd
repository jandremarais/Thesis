# Multi-Label Learning

## Introduction

+ why this chapter
+ aim is to cover the core of MLL literature
+ update of previous reviews
+ to highlight areas to focus on for further studies

> cannot find good literature on multi-target learning - might not want to add the above paragraph

The birth of the ML field (around 1999) came from the need to assign multiple labels to text documents. Contributions in [@Schapire99improvedboosting] and [@Schapire2000a] adapted a boosting algorithm to handle ML data. [@Elisseeff] defined a ranking based SVM to deal with ML problems in the areas of text mining and also bioinformatics. [@Lewis2004] released an important benchmark collection for ML text classification. Another highly cited ML SVM implementation is [@Boutell2004a], with application in scene/image classification. [@Zhang2006] showed how to apply neural networks to a ML problem and [@Zhang2007] adapted the KNN algorithm for ML input. The first overview on the subject was given in [@Tsoumakas] where the author discussed the most relevant ML learning approaches. Then came applications to music, [@Trohidis2008] and [@Turnbull2008]. [@Vens2008] showed how to use decision trees for hierarchical ML classification. Important papers introducing unique ML approaches are [@Tsoumakas2007b], [@Furnkranz2008] and [Read2011a]. A crucial step for ML learning was to make it accesible and useable to more reasearchers. The authors of [@Tsoumakas2011] developed a Java library for ML learning. Later on [@Madjarov2012a] did a empirical study on the most important ML algorithms up to that date, comparing 12 multi-label learning methods using 16 evaluation measures over 11 benchmark datasets. More recent extensive reviews of ML learning are given in [@Zhang2014] and [@Gibaja2014]. 

> not sure which papers to include here. The aim is to highlight the most important. Difficult to determine. Should I visualise timeline of contributions?

> what does recent research focus on? Extreme ML learning?

The rapid growth of the ML learning is probably owed to the vast and expanding range of ML application domains, the biggest being text and multimedia categorisation especially those generated and/or stored on the web. Other application domains common to ML learning are: biology, chemical data analysis, social network mining and E-learning amongst others. A thorough list of applications and their citations can be found in [@Gibaja2014].

> Say something of video classification? Create my own list of applications?

The key challenge in ML learning is to exploit dependecies amongst labels, *e.g.* using the information on the relevance of label $l_{i}$ to predict label $l_{j}$, $i,j \in \{1,2,\dots,K\}$, $i\neq j$. This is especially difficult for a ML learner when there are many labels. It is not uncommon for ML datasets to have hundreds of thousands of labels. Proof of this can be found at [this](https://manikvarma.github.io/downloads/XC/XMLRepository.html) ML data repository. Algorithms that can accurately and efficiently model label dependence on these datasets are rare [@Sorower]. This is a focus area of recent ML research, called extreme multi-label learning [@Xu2016]. A more formal definition of label dependence will be given later on. An in-depth discussion on the unique challenges (thorough list by [@Gibaja2014]) that arise from dealing with label dependence and some of the possible strategies to follow will also be covered.

### Basic Idea

### Applications

+ thorough list by [@Gibaja2014]
+ text; multimedia; biology; chemical data analysis; social network mining; e-learning; other
+ examples and citations
+ mention importance

### In the Literature

+ history
+ database analysis
+ show trend
+ most cited papers
+ mention important reviews:

[@Tsoumakas2007], [@Sorower], [@Zhang2014], [@Gibaja2014], Tutorial: [@CarvalhoAndreCPLFde2009], [@Gibaja2015]

+ see [@Gibaja2015] for different MLL resources 

### Challenges and Ongoing Research

+ key challenge = output space
+ mention challenges casused by key challenges
+ from [@Gibaja2014]
+ worth highlighting that recent research has shifted its focus to problems on large scale labels - focus on scalability
+ Label Dependence: conditional vs marginal; mentions order categorisation; asymetric and local
+ Dimensionality Reduction
+ Reduction of the Input Space: feature selection; feature extraction
+ Reduction of the Output Space: HOMER; Label reduction with association rules; CCA; compressed sensing; principal label space transform; compressed labelling
+ MIML
+ Semi-supervised and Active Learning
+ Online MLL and Data Streams
+ Hierachical MLC
+ Dealing with Class Imbalance: label skew
+ Mention extreme MLC and maybe add a section somewhere in chapter
+ list also in [@Alazaidah2016]

### Aim of this Chapter

+ the goal of this chapter: review + highlight limitations to be studied further
+ outline

## The Paradigm

+ consider adding the settings described by Read and [@Gibaja2015]

### Learning Framework



### Multi-Label Data and Repositories

+ properties of a ML data set: label cardinality, label density, label diversity
+ Simulating [@TorresTomas2014] (also gives citations to other papers)
+ above has no control over label correlation
+ partitioning mentioned in [@Gibaja2015] - referred to [@Sechidis]
+ [@Sorower]
+ details of benchmark datasets in appendix (learn how to link)

### Key Challenge

+ key challenge is the size of the output space: label sets grows exponentially with increase in labels
+ solution is to exploit label correlations efficiently
+ [@Sorower] has a section on exploiting label dependence
+ mention label dependence chapter
+ first-order, second-order, high-order strategies grouping

### Threshold Calibration

+ calibrate real-valued output against thresholding function output in order to determine labels of unseen instances.
+ constant vs induced from training data + ad hoc specific to certain learning algorithms
+ alternative to choose top k labels

## Evaluation Metrics



## Learning Algorithms

### Simple Catergorisation

There are numerous multi-label learning algorithms. It is difficult to keep up with the all the latest proposed methods. These algorithm can be categorised in a number of ways, *e.g.* the review [@Zhang2014] and the tutorials [@Gibaja2015] and [@CarvalhoAndreCPLFde2009], all have different ways of grouping the algorithms. The categorisation for this thesis is chosen to satisfy the criteria of being common, simple and intuitive. Nevertheless, the characteristics of the algorithms leading to the other grouping variants will still be given in the remarks of the algorithms.

```{r mll-tax, eval=FALSE, include=FALSE}
library(DiagrammeR)
library(DiagrammeRsvg)
library(magrittr)
library(svglite)
library(rsvg)
library(png)

grViz('figures/MLL-tax.gv') %>% export_svg() %>% 
  charToRaw %>% rsvg %>% png::writePNG('figures/mll-tax.png')
```

![Categorisation of multi-label learning taxonomy (this is just an example) \label{fig:mll-tax}](figures/mll-tax.png)

+ still need to edit \autoref{fig:mll-tax}

+ want to keep it simple and representative but also give table with full list of methods
+ many proposals
+ scrutinise 8 representative algorithms for feasibility concerns
+ representativeness criteria: broad spectrum; primitive impact; favourable impact
+ introduce PT vs AA
+ diagram of categorisation
+ very thorough one in [@Gibaja2015]
+ mention ensemble category

### Problem Transformation Methods

Problem transformation methods consist of first transforming the multi-label problem into one or more single-label problem(s) and then fitting any standard supervised learning algorithm(s) to the single-label data. For that reason, problem transformation methods are called algorithm independent, i.e. once the data is transformed, any single-label classifier can be used [@Tsoumakasc].

The two main problem transformation algorithms are the binray relevance and label powerset transformations. Both methods suffer from several limitations but they form the basis of arguably any problem transformation method. The state-of-the-art problem transformations algorithms are most of the times extensions of either the standard binary relevance or label powerset algorithms [@Alazaidah2016]. Therefore the understanding of these two basic methods are crucial in dealing with the more complex, modern problem transformation methods.

#### Binary Relevance

+ basic idea
+ notation
+ cross-training
+ T-criterion for avoiding empty prediction
+ psuedo-code
+ remarks: first-order; parallel; straightforward; building block of state-of-the-art; ignores potential label correlations; may suffer from class-imbalance; computational complexity

The most common transformation method is binary relevance (BR). BR transforms the mutli-label into $K$ single-label problems by modelling the presence of the labels separately. Typically $K$ single-label binary data sets, $D_{k}=(X,\boldsymbol{Y}_{k})$ for $k=1,...,K$, would be constructed from the multi-label data set, $D=(X,Y)$. To each $D_{k}$ any single-label classifier can be applied. In the end, predictions $\hat{\boldsymbol{Y}}_{1},...,\hat{\boldsymbol{Y}}_{K}$ are obtained separately which can then be combined to allocate all the predicted relevant variables to each instance. Note, that it may occur that all of the single-label learners produces zeroes, which would imply that the instance belongs to an empty set. To avoid this [@Zhang2014] suggests following the T-criterion rule. The rule states, briefly, that in such a case the labels associated with the greatest output should be assigned to the instance. Clearly, this will only work if the base learners used gives continuous outputs and it will only make sense if all the base learners are of the same type. I suppose these rules are ad-hoc and I can think of alternatives.

> With this approach the standard single label feature selection procedures can be applied. The relevant subset of features can be identified for each label. This is convenient since it is not unlikely that the optimal subset of features will differ from label to label.

The biggest drawback for this approach is that it models each label separately and ignores the possible correlations between labels. Thus BR assumes that there are no correlations between the labels. However, these correlations can be very helpful in predicting the labels present. This is a first-order strategy. Also it can be time consuming since data sets with hundreds of labels is not rare. This would mean more than a hundred models should be fit and tuned separately. But this complexity scales linearly with increasing $K$, which is actually not so bad when comparing to other multi-label algorithms. Grouping the labels in a hierachical tree fashion may become useful when $K$ is very large [@Cherman2011] (see also Incorporating label dependency into the binary relevance framework for multi-label classification by the same authors).

Another argument against BR from [@Readb]: The argument is that, due to this information loss, BR's predicted label sets are likely to contain either too many or too few labels, or labels that would never co-occur in practice.

Advantage of BR by [@Readb]:
Its assumption of label independence makes it suited to contexts where new examples may not necessarily be relevant to any known labels or where label relationships may change over the test data; even the label set $L$ may be altered dynamically - making BR ideal for active learning and data stream scenarios.

Nevertheless, BR remains a competitive ML algorithm in terms of efficiency and efficacy, especially when minimising a macro-average loss function is the goal [@Luaces]. The most important advantage of BR is that it is able to optimise several loss functions [@Luaces] also see small proof. They also show empirically that BR tends to outperform ECC when there are many labels, high label dependency and high cardinality, i.e. when the multi-label data becomes more complicated.

Compared to label powerset (LP) which will be discussed later, BR is able to predict arbitrary combinations of labels [@Tsoumakasb] not restricted only to those in the training set.

[@Cherman2011] also proposes a variation of BR called BR+. Its aim is to keep the simplicity of BR but also to consider the possible label correlations. It does so by also creating $K$ binary data sets but this time each of these data sets treat all the label columns not to be predicted by the current single-label classifier as features to the classifier. Thus each sinlge-label classifier will have $p + K - 1$ inputs. So now when predicting label $l$, all of the original features in $X$ and the remaining variables $\boldsymbol{Y}_{k}$, $k\neq l$, are used as inputs for classifier $l$. (second order strategy?)

The problem arises when predicting unseen instances for which the labels are unknown. Thus the input needed for each binary classifier is not available. One workaround is to obtain an initial prediction of the labels using an ordinary BR approach and then using these predictions as inputs to the BR+ algorithm. The BR+ algortihm will most likely produce different predictions to the initial predicitons or BR which can then also be used in a next round of BR+. These steps can be continued until convergence but this seems like the classifier chains approach. (to be investigated).

[@Tsoumakasb] mentions the 2BR strategy that seems very similar/identical to BR+. They describe the 2BR method as follows: first train a binary classifier on each of the $K$ binary data sets and then use their predictions (and or probabilities) as so called meta-features for a second round of BR. They mention that it might be better to train the base and meta learners on separate parts of the training data to avoid biased predictions. They suggest using a cross-validation approach for both learners to also avoid size constraints of the training data. They describe this approach as a stacked generalisation, also mentioned in [@Tsoumakasa], [@Godbole], [@Pachet2009] calls it classifier fusion.

The adding of all the base learner predicitions as meta-feature to the meta-learners is not necessarily desirable. Some label pairs might have no correlation and adding predictions for those labels as inputs to the meta-learner will add noise to the model and waste computation time. [@Tsoumakasb] suggests a solution called corerlation-based pruning. They calculate the pairwise correlations between labels, $\phi$, and only add base learner prediction of label $i$ as a meta-feature to meta-learner $j$ if $\phi_{ij}$ is greater than some threshold. In this way only label-pairs that are highly correlated will be used in the final prediction of each other.

+ BR performs well for Hamming loss, but fails for subset 0/1 loss.
+  It is not clear, in general, whether the meta-classifier b should be trained on the BR predictions h(x) alone or use the original features x as additional inputs. Another question concerns the type of information provided by the BR predictions. One can use binary predictions, but also values of scoring functions or probabilities, if such outputs are delivered by the classifier @[@Dembcz2012].


#### Classifier Chains

+ basic idea
+ notation
+ importance of ordering
+ ECC brief explanation
+ psuedo-code
+ remarks: high-order; considers label correlations in a random manner; not parallel; computational complexity

Another extension of BR, similar to 2BR and BR+, is the classifier chains (CC) approach introduced by [@Readb]. It also consists of transforming the mutli-label data set $D$ to $K$ single-label data sets but the transformations are done sequentially in the sense that the label previously treated as a response will be added as a feature for predicting the next label. This will give data sets similar to $D_{1}=(X,\boldsymbol{Y}_{1}),D_{2}=(X,\boldsymbol{Y}_{1},\boldsymbol{Y}_{2}),...D_{K}=(X,\boldsymbol{Y}_{1},\boldsymbol{Y}_{2},...,\boldsymbol{Y}_{K})$, where the last column of each is the response that needs to be predicted. To each of these single-label data sets a classifier can be trained and then their predictions are combined in the same fashion as BR. CC keeps the simplicity of BR but has that additional capacity to model label dependencies by passing label information between classifiers. This should raise the question of what order of labels should the chain consist of and should it stop after one cycle?

In a response to this, the ensembles of classifier chains (ECC) was suggested by [@Readb]. Here the term ensemble refers to an ensemble of multi-label classifiers instead of an ensemble of binary classifiers already mentioned before. ECC trains $m$ classifier chains, each with a random chain ordering and a random subset of instances. These parameters of ECC contributes to the uniqueness of each classifier chain which helps with variance reduction when their predictions are combined. These predictions are summed by label so that each label receives a number of votes. A threshold is used to select the most popular labels which form the final predicted multi-label set [@Readb] (copied from). More details still to cover in article.

CC and ECC has an advantage over the ensemble methods of BR, that it is not necessary for an initial step of training to obtain predictions of labels that can later be used as features, it does this simultaneously.

Paper still need to look at for CC [@Sucar2013].

#### Calibrated Label Ranking

+ basic idea
+ notation
+ process for unseen instance
+ threshold function
+ enriched version of pairwise comparison
+ psuedo-code
+ remarks: second-oder; one-vs-one; mitigates class imbalance issue; quadratic increase in classifiers and improvements thereof; computational complexity

#### Random k-Labelsets

+ basic idea
+ notation
+ LP
+ limitations of LP: incompleteness and inefficiency
+ why rakel improves it
+ psuedo-code
+ remarks: high-order; ensembling; computational complexity

The other widely known problem transformation approach is the label powerset (LP) algorithm. Each combination of the labels is seen as a distinct class and then a standard multiclass classification learner can be applied. More formally, the transformation $h:L\to P(L)$ is applied [@Tsoumakasc]. Thus label correlations are taken into account but LP has other limitations. The number of possible classes increase exponentially with the increase in $K$ and some of the classes/combinations are under-represented (if represented at all) in the training set. This leads to the difficult problem of learning from unbalanced classes and also restricts the algortihm to only predict combinations of labels present in the training set. Labels (or labelsets) that only occur a limited number of times are called tail labels. These are generally the ones difficult to model and a classifier can easily neglect their importance [@Xu2016].

One way to reduce the number of resulting classes after a label powerset transformation is to create meta-labels (not to be confused with meta in the stacking sense) [@Read]. Meta-labels represent partitions of the label set, but I still do not fully understand the concept. Seems like after the transformation we still end up with a multi-label problem. Investigate further.

Another option is to throw away the combinations that appear infrequently in the training set. This obviously limits the possible output of the mutli-label algorithm even more. Sounds like PPT [@Reada].

The best way, according to the literature [@Zhang2014], to overcome the two main limitations of LP is another ensemble based approach (similar idea to stacking) called random $k$-labelsets (RA$k$EL). It was first introduced in [@Tsoumakasc]. It reduces the number of classes to predict from and allows each class to have more training instances compared to the LP method [@Lo2013]. Each learner in the ensemble constructs an LP classifier from a random subset of $k$ labels, referred to as $k$-labelsets. The randomness of this approach can also be its downfall, since the chosen subsets may not cover all labels and inter-label correlations [@Rokach]. We will use the term $L^{k}$ to denote the set of all distinct $k$-labelsets on $L$. The size of $L^{k}$ is given by $|L^{k}| = {{|L|}\choose{k}}$. The RA$k$EL algorithm iteratively constructs $m$ LP classifiers from a randomly select $k$-labelset, where each $k$-labelset is sampled from $L^{k}$ without replacement. The parameters to be tuned for RA$k$EL is the size of the ensemble (number of iterations), $m$, and the size of the labelsets, $k$. If $k=1$ and $m=|L|=K$ this is just an ensemble of BR classifiers. If $k=|L|$ then it becomes the ordinary LP method. [@Tsoumakasc] suggests a small $k$ with a sufficient number of ensembles, $m$, which they show to manage label correlations efficient- and effectively.

To make a prediction on a new instance, the new instance is feeded to each classifier in the ensemble and then their outputs are combined. To determine if label $j$ is relevant for this new instance, the proportion of classifiers in the ensemble indicating that label $l$ is relevant is obtained and then the final output is 1 if this proportion is greater than some threshold $t$. Intuitively $t=0.5$ makes sense, since this is equivalent to a majority vote, but RA$k$EL has been shown to work for a wide range of $t$-values.

Another factor to consider is the value of $k$. We do not want it to big. Also how many models should be included in the ensemble?

There are other ways of choosing subsets of the labelset, references in [@Rokach].

Note, with all these ensemble extensions, we can still try different ways of ensembling/stacking, especially with RA$k$EL. Not only taking the average but also by assigning weights to each model or by fitting a model to the predictions. Think [@Lo2013] is an example of this with generalised $k$-labelsets ensemble.

+ LP takes the label dependence into account, but the conditional one: it is well-tailored for the subset 0/1 loss, but fails for the Hamming loss. 
+ LP may gain from the expansion of the feature or hypothesis space.
+ One can easily tailor LP for solving the Hamming loss minimization problem, by marginalization of the joint probability distribution that is a by-product of this classifier.

### Algorithm Adaption Methods

These are methods tackling the multi-label learning task by adapting, extending and/or customising an existing supervised learning algorithm [@Madjarov2012a]. 

The main weakness of algorithm adaption methods is that they are mosty tailored to suit a specific model, whereas problem transformation methods are more general and allows for the use of many well-known and effective single-label models [@Rokach] (algorithm independent).

#### Multi-Label k-Nearest Neighbour (ML-kNN)

+ basic idea
+ procedure
+ psuedo-code
+ remarks: first-order; merits of lazy learning and Bayesian reasoning; mitigate class-imbalance; extensions/variations; computational complexity

#### Multi-Label Decision Tree (ML-DT)

+ basic idea
+ procedure
+ psuedo-code
+ remarks: first-oders; efficient; improve with pruning and or ensembling; computational complexity

#### Ranking Support Vector Machine (Rank-SVM)

+ basic idea
+ procedure
+ psuedo-code
+ remarks: second-order; variants; computational complexity

#### Collective Multi-Label Classifier (CML)

+ basic idea
+ procedure
+ psuedo-code
+ remarks: second-order; conditional random field model; DAG; computational complexity

### Summary

+ table: basic idea; order; complexity (test/train); domains; optimised metric
+ interpretation
+ comment on applicability to data sets
+ first-order AA is not BR

## Related Learning Strategies

+ multi-instance
+ ordinal classification
+ multi-task learning
+ data streams classification
+ multi-task learning; multiple-labels learning; multi-intance learning; reverse multi-label learning; preferential text classification; weak label problem; multi-valued multi-label; graded multi-label; multi-view learning

## Pitfalls and Guidelines

+ choosing algo is hard
+ more empirical evidence is needed; with with wide range of data sets, algos and measures; compare with statistical tests and consider computation time (training and test)
+ part on statistical tests in [@Gibaja2015]
+ gives reccomendations from empirical study
+ mentions label dependence modelling from dembcsz
+ trees for efficiency, ensembles for predictive performance, transformation methods for flexibility

## Conclusion

+ what was done in the paper
+ no formal charaterisation on the underlying concept or any principled mechanism on the appropriate usage of label correlations
+ correlations might be asymmetric and or local
+ label correlation understanding is holy grail of ML
+ complement of this paper would be a broad empirical study

+ what follows in next chapter(s)
+ highlight challenges again and mention those we are going to focus on: label dependence, high dimensionality
+ consider the addition of empirical study 
+ will actually contribute empirically but with specific questions in mind (end of each chapter)











