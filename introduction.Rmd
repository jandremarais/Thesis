# Introduction
\label{chp:intro}

## Motivation

The motivation for this thesis is two-fold:

1. Image classification is a highly relevant topic in Computer Vision, Machine Learning and Statistical Learning. It is a thoroughly researched domain and already by many regarded as a 'solved' problem. This progress is mainly attributed to the yearly large-scale image classification competition, *ImageNet*[^imagenet], and the development of *Deep Neural Networks* (DNNs), and more specifically, *Convolutional Neural Networks* (CNNs). The last five winners of ImageNet all used a variant of CNNs in their solution. However, the main focus up until recently was on problems of single label classification. Therefore, the field of multi-label image classification is nowhere near the maturity level of its single-label counterpart. Multi-label classification has a wide range of applications, not only in image classification. It has been applied to problems in text categorisation, multimedia, biology, chemical data analysis, social network mining and e-learning among others. This is most likely the reason why it has seen such a rapid increase of academic publications (see \autoref{pubsperyear}). However, researchers have not yet reached consensus on how to deal with many of the aspects when learning from multi-labelled data, *e.g.* dependency between labels. There are a very limited number of publications specifically dealing with multi-label classification of images, even more so while using DNNs for this task. The field can gain from an up-to-date review of the literature, more statistical perspectives on some of the challenges, additional benchmark datasets and quality empirical evaluations of the theory.  

```{r pubsperyear, include=FALSE, eval = FALSE}
library(tidyverse)
library(ggthemes)
pubsperyear_data <- read_csv("data/Scopus-2251-Analyze-Year.csv")
p <- pubsperyear_data %>% gather(database, No, -YEAR) %>% 
  #mutate(ind2017 = YEAR >= 2017) %>% 
  filter(YEAR < 2017) %>% 
  ggplot(aes(YEAR, No)) +
  geom_line() +
  theme_minimal() +
  labs(x = "Year", y = "# Documents") +
  facet_wrap(~database, labeller = function(variable, value) {
    dnames <- list(Scopus = "(a) Scopus", SemSchol = "(b) Semantic Scholar")
    return(dnames[value])}) 

ggsave("pubsperyear.png", plot = p, device = "png", path = "figures", width = 7, height = 4)
```

![Line graphs illustrating the rise in multi-label learning publications per year for two databases. The database searches were done on 24-03-2017. The searches were not identical since they were limited to the search features of the databases. (a) The search on Scopus (cite) was for all documents (conference papers, articles, conference, articles in press, reviews, book chapters and books) in any subject area with either the words *multi-label* or *multilabel* and either the words *learning* or *classification* found in either their titles, abstracts or keywords. (b) The search on Semantic Scholar was based on machine learning principles and thus automatically decides which research documents are relevant to a specific search query. The query used was *multilabel multi-label learning classification*. The search only returns research in the computer science and neuroscience fields of study. More technical details can be found on the respective engine's websites. \label{pubsperyear}](figures/pubsperyear.png)

2. Deforestation is a massive global problem. It contributes to reduced biodiversity, habitat loss, climate change and other devastating effects. It is said that the world loses an area of forest the size of 48 football fields per minute and the area most affected is in the Amazon basin (cite Kaggle). This problem can be fought more effectively by governments and local stakeholders if better data about the location of deforestation and human invasion on forests are continuously available to them - an ideal task for machine learning! Planet[^planet] and SCCON[^sccon] constructed a dataset of labelled satellite images taken of the Amazon basin and released it as part of a competition on Kaggle[^kaggle], challenging competitors to build algorithms that can automatically label these images with atmospheric conditions and various classes of land use/cover[^usecover]. Resulting algorithms will help the global community better understand where, how, and why deforestation happens all over the world - and ultimately how to respond. A solutions for this task will also contribute to the more broader domain of *Remote Sensing* which could roughly be understood as the analysis of satellite imagery. Again, this domain has many other relevant applications, especially with environmental and infrastructural benefits. For example estimating water and oil reserves, analysing the traffic or determining areas with high poverty, all from just satellite images. (get citations)

[^imagenet]: http://www.image-net.org/
[^planet]: Designer and builder of the world's largest constellation of Earth-imaging satellites - www.planet.com
[^sccon]: Remote sensing experts - www.sccon.com.br/eng
[^kaggle]: Runs programming contests to crowd source machine learning solutions - www.kaggle.com
[^usecover]: Land cover indicates the physical land type such as forest or open water whereas land use documents how people are using the land.

In summary, the relevance in terms of practial and meaningful applications of the topics Multi-Label Classification and Remote Sensing is the main motivation behind this research. Both these research areas are still in their fledgeling phases which also contributes to this choice in research direction. The exact topics to be covered will be given in the next section discussing the aim of the thesis.

## Thesis Objectives

This thesis works towards building a multi-label classifier that can label satellite images of the Amazon as accurately as possible. The method thought best to achieve this goal is to:

1. Identify the most important and latest developments in the literature for: multi-label classification and image classification for remote sensing.
2. Provide an extensive review and discussion of these methods and how they compare to each other.
3. Empirically evaluate and compare them on the satellite image data in order to find the best strategies for our labeling task.

Since practically every state-of-the-art solution to an image classification problem is a CNN, it is reasonable to restrict the space of possible classifiers to CNNs. This thesis should provide the reader with a clear understanding of CNNs and how to effectively apply them to a multi-label classification problem, and especially in the domain of remote sensing. The main contribution of this thesis is a review of multi-label CNNs.

> update this section as progress is made with thesis.

> maybe be more specific

## The Problem

Although the review and evaluation of the literature is the main goal of this thesis, the task of the competition on Kaggle is a secondary objective and what we will use to give our research and discussion direction. Since it is real world example, it will give us a good idea of the needs in practice and thus we can build our research around that. The methods learned to optimise our objective will most likely be transferable to other similar problems.

The task of the competition on Kaggle can be summed up as follows. The competitor is given a training set of satellite images of the Amazon, labelled with various land use and cover labels. The goal is to train a model to learn the relationships between images and labels in order to predict the correct labels for the unlabelled set of satellite images as accurately as possible. This is a typical *supervised learning* task in Statistical Learning and since the output is categorical, this is a *classification* problem. A mathematical definition will be given soon. But first we will investigate the data for this task.

To define the problem more precisely, we follow the conventions of [@Hastie2009]. Let $\boldsymbol{X}\in \mathbb{R}^{p}$ denote a real valued random input vector and $G\in \mathcal{G}$ a categorical variable taking on classes in $\mathcal{G}$. They have a joint distribution $P(\boldsymbol{X},G)$. We seek a function $f(\boldsymbol{X})$ for predicting output $G$ given input $\boldsymbol{X}$. To evaluate the error of the prediction made by $f$ we use a loss function $L(G,f(\boldsymbol{X}))$. Obviously, we want this error made by $f$ to be as small as possible, thus our aim is to minimise the criterion called the expected prediction error:

$$
\mathrm{EPE}=\mathbb{E}\left[L\left(G,f(X)\right)\right]
$$

> not sure how I want to define this and in how much detail?
> give formal definition and explain how it relates to practical problem.
> Introduce f-measure?
> maybe first only cover single label classification

## The Data

This section covers an initial introduction to the data available for the problem at hand. The elements of the data important to know before moving on will be discussed here and the rest will be addressed throughout the thesis, as it becomes relevant to the discussion. This is done here to get a better understanding of the problem before exploring the literature.

### Image Format

The data for this task comes from a set of images (also referred to as chips). Each chip is a small excerpt from a larger image of a specific scene in the Amazon taken by satellites. The chip size in pixels is $256\times 256$, representing roughly 90 hectares of land, and is taken from a larger scene of $6600\times 2200$ pixels. All of the satellite images were taken between January 1, 2016 and February 1, 2017. The format of these images differ from the standard image format. Each image contains four spectral bands: red (R), green (G), blue (B) and near infrared (NIR), where the standard format images usually only contain R, G and B. The additional NIR colour channel is common in remote sensing[^remsens] applications and supposedly allows for clear distinction between water and vegetation in satellite images, for example. 

Another difference between these images and the usual format is that these have pixel intensities in 16-bit digital number format as opposed to the usual 8-bit of standard RGB images. This allows the colours in the images to have a much higher range since 16-bit pixel intensities have 65536 ($2^{16}$) levels, compared to 256 levels of 8-bit images. This becomes useful, for example, to distinguish between very dark or very bright areas in an image. If the pixel values of a chip gets flattened out into a vector, it will be of size 262144 ($256\times 256 \times 4$). However, CNNs take the images in their array form as input.

[^remsens]: The use of satellite- or aircraft-based sensor technologies to detect and classify objects on Earth [https://en.wikipedia.org/wiki/Remote_sensing].

### Collection and Labelling of the Images

The image collection was created by first specifying a "wish list" of scenes containing the phenomena the creators wanted to be included, in addition to a rough estimate of the number of such scenes that are necessary for a sufficient representation in the final collection. This set of scenes was then searched for manually on Planet Explorer[^planexp]. From these scenes the 4-band chips were created. A schematic of this process can be seen in \autoref{fig:chipcreate}. The chips were labelled manually by crowd sourcing. The utmost care was taken to get a large and well-labelled dataset, but that does not mean the labels all correspond to the ground-truth, *i.e.* the data will contain some inherent error. The creators believe that the data has a reasonable high signal to noise ratio.

![Schematic of the image collection process.\label{fig:chipcreate}](figures/chipdesc.jpg)

[^planexp]: A web based interactive map of Earth consisting of satellite images, similar to Google Earth - www.planet.com/explorer

Note, the training and test splits were determined by the Kaggle competition creators. The training chips are labeled but at the time of writing this, the test chips are not yet made available to competitors. Predicted labels for the test chips can be submitted to Kaggle to evaluate in terms of the $F_{2}$-score, a metric which will be discussed in Chapter ??. This setup prevents competitors from using the test chips for training a classifier. There are 40479 training chips and 61191 test chips.

### Class Labels

The class labels for the images can be divided into three groups: atmospheric conditions, common land cover/use phenomena and rare land cover/use phenomena. In total there are 17 posssible labels. Each chip will have one atmospheric label and zero or more common and rare labels. Chips that are labeled as cloudy should have no other labels.

The atmospheric condition labels are: *clear*, *haze*, *partly cloudy* and *cloudy*. They are relevant to a chip when:

+ **clear**: there are no evidence of clouds.
+ **haze**: clouds are visible but they are not so opaque as to obscure the ground.
+ **partly cloudy**: scenes show opaque cloud cover over any portion of the image but the land cover/use phenomena are still visible.
+ **cloudy**: 90% of the image is obscured with opaque cloud cover.

```{r, include=FALSE, eval = FALSE}
library(tidyverse)
library(stringr)
train_labels <- read_csv("~/Documents/Kaggle/Amazon/train.csv")
label_list <- strsplit(train_labels$tags, " ")

atmos_labels <- c("clear", "haze", "partly_cloudy", "cloudy")
atmos_files <- lapply(atmos_labels, function(a) {
  lab_ind <- sapply(label_list, function(b) a %in% b)
  train_labels$image_name[lab_ind][1:3]
})

library(jpeg)
atmos_paths <- lapply(atmos_files, function(a) paste0("~/Documents/Kaggle/Amazon/train-jpg/", a, ".jpg"))
atmos_imgs <- lapply(atmos_paths, function(a) lapply(a, readJPEG))
library(ggmap)
library(gridExtra)
atmos_grobs <- lapply(atmos_imgs, function(a) lapply(a, ggimage))

grobs_arranged <- lapply(1:length(atmos_grobs), function(a){
  arrangeGrob(grobs = atmos_grobs[[a]], ncol = length(atmos_grobs[[a]]), respect = TRUE, left = atmos_labels[a])
})

ggsave("figures/atmos.png", grid.arrange(grobs = grobs_arranged, ncol = 1))
```

![Examples of chips with atmospheric labels. These (along with all the other chips plotted throughout the thesis) are the JPEG conversions of the original 4-band, 16-bit images.\label{fig:atmos-egs}](figures/atmos.png)

Examples of chips with atmospheric labels can be found in \autoref{fig:atmos-egs}. Each chip should only have one atmospheric label and therefore this classifying task simplifies to a multiclass problem. This allows for the option to break up the labeling task of all the labels into two tasks: a multiclass classification problem for the atmospheric labels and a multi-label classification problem for the land cover/use labels. This approach might save some computational time and give extra information to the multi-label learners for classifying the land cover/use labels. We will experiment with these approaches in Chapter ??.

The common land cover/use labels are: *primary*, *agriculture*, *water*, *habitation*, *road*, *cultivation* and *bare ground*. They are relevant to a chip when:

+ **primary**: it is primarily consisting of rain forest (virgin forest), *i.e.* dense tree cover.
+ **agriculture**: it contains any land cleared of trees that is being used for agriculture or range land.
+ **water**: it contains any one of the following: rivers, reservoirs, or oxbow lakes.
+ **habitation**: it contains human homes or buildings.
+ **road**: it contains any type of road.
+ **cultivation**: it shows signs of smaller-scale/informally cleared land for farming.
+ **bare ground**: it contains naturally (not the caused by humans) occurring tree-free areas.

```{r, include=FALSE, eval = FALSE}
common_cover_labels <- c("primary", "agriculture", "water", "habitation", "road", "cultivation", "bare_ground")
common_cover_files <- lapply(common_cover_labels, function(a) {
  lab_ind <- sapply(label_list, function(b) a %in% b)
  train_labels$image_name[lab_ind][1:3]
})

common_cover_paths <- lapply(common_cover_files, function(a) paste0("~/Documents/Kaggle/Amazon/train-jpg/", a, ".jpg"))
common_cover_imgs <- lapply(common_cover_paths, function(a) lapply(a, readJPEG))
common_cover_grobs <- lapply(common_cover_imgs, function(a) lapply(a, ggimage))

grobs_arranged <- lapply(1:length(common_cover_grobs), function(a){
  arrangeGrob(grobs = common_cover_grobs[[a]], ncol = length(common_cover_grobs[[a]]), respect = TRUE, left = common_cover_labels[a])
})

ggsave("figures/common-cover.png", grid.arrange(grobs = grobs_arranged, ncol = 1))
```

![Examples of chips with common land cover/use labels. \label{fig:common-cover-egs}](figures/common-cover.png)

Examples of chips with common land cover/use labels are found in \autoref{fig:common-cover-egs}. According to the competition page on Kaggle, small, single-dwelling habitations are often difficult to spot but usually appear as clumps of a few pixels that are bright white. Roads sometimes look very similar to rivers and therefore these two labels might be noisy. The NIR band might give a classifier additional information to help distinguish between the two. Cultivation is a subset of agriculture and is normally found near smaller villages, along major rivers or at the outskirts of agricultural areas. It typically covers very small areas.

The less common land cover/use labels are: *slash and burn*, *selective logging*, *blooming*, *conventional mine*, *artisinal mine* and *blow down*. Chips are tagged with these labels when:

+ **slash and burn**: there are signs of the farming method that involves the cutting and burning of the forest to create a field. These look like cultivation patches with black or dark brown areas.
+ **selective logging**: winding dirt roads are present adjacent to bare brown patches in otherwise primary rain forest. Selective logging is the practice of selectively removing high values tree species from the rainforest.
+ **blooming**: there are signs of trees flowering. Blooming is a natural phenomena where particular species of flowering trees bloom, fruit and flower at the same time. These trees are quite big and the phenomena can be seen in the chips. They usually appear as white dots.
+ **conventional mine**: it contains signs of large-scale legal mining operations.
+ **artisinal mine**: it contains signs of small-scale (sometimes illegal) mining operations.
+ **blow down**: there are signs of trees uprooted or broken by wind. High speed winds (~160km/h) in the Amazon are generated when the cold dry air from the Andes settles on top of the warm moist air in the rainforest and then sinks down with incredible force, toppling larger rainforest trees. These open areas are visible from space.

```{r, include=FALSE, eval = FALSE}
rare_cover_labels <- c("slash_burn", "selective_logging", "blooming", "conventional_mine", "artisinal_mine", "blow_down")
rare_cover_files <- lapply(rare_cover_labels, function(a) {
  lab_ind <- sapply(label_list, function(b) a %in% b)
  train_labels$image_name[lab_ind][1:3]
})

rare_cover_paths <- lapply(rare_cover_files, function(a) paste0("~/Documents/Kaggle/Amazon/train-jpg/", a, ".jpg"))
rare_cover_imgs <- lapply(rare_cover_paths, function(a) lapply(a, readJPEG))
rare_cover_grobs <- lapply(rare_cover_imgs, function(a) lapply(a, ggimage))

grobs_arranged <- lapply(1:length(rare_cover_grobs), function(a){
  arrangeGrob(grobs = rare_cover_grobs[[a]], ncol = length(rare_cover_grobs[[a]]), respect = TRUE, left = rare_cover_labels[a])
})

ggsave("figures/rare-cover.png", grid.arrange(grobs = grobs_arranged, ncol = 1))
```

![Examples of chips with less common land cover/use labels. \label{fig:rare-cover-egs}](figures/rare-cover.png)

Examples of chips with these less common land cover/use labels are given in \autoref{fig:rare-cover-egs}. These labels are more challenging to identify in the chips and since they also appear less frequently, it might be difficult for the classifier to learn these labels. The imbalance in the class distribution is apparent in \autoref{fig:classdist}.

```{r, cache=TRUE, echo=FALSE, fig.cap="Class distribution of the labels in the training set. \\label{fig:classdist}"}
library(tidyverse)
library(stringr)
train_labels <- read_csv("data/train_v2.csv")
label_list <- strsplit(train_labels$tags, " ")

as.data.frame(table(unlist(label_list))) %>% 
  rename(Label = Var1) %>% 
  mutate(Label = factor(Label, levels = Label[order(-Freq)])) %>% 
  ggplot(aes(Label, Freq)) +
  geom_histogram(stat="identity") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1)) +
  ylab("Frequency") #+ ggtitle()
```




