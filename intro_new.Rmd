# Introduction
\label{chp:intro}

## Motivation \label{sec:moti}

> the core of what I want to say here is that multi-label image classification is chosen because it has many useful applications. Deep neural networks is chosen because it is the most powerful single label image classification model. The combination is also new research area with potential of contributing to literature. Make sure this is what this section communicates.

*Image Classification* is the task of assigning one (or more) label(s) to an input image. It is one of the core problems in *Computer Vision*. This seemingly simple task has a large variety of practical applications. For example, detecting deforestation in the Amazon from satellite images [^Amazon] or detecting cancer from images of skin lesions taken by a mobile phones [@Esteva2017]. Image classification is a thoroughly researched subject and already regarded by many as a 'solved' problem. This progress is mainly attributed to the yearly large-scale image classification competition, called *ImageNet*[^imagenet], providing researchers with millions of labelled images to train their image classification models.

[^Amazon]: https://www.kaggle.com/c/planet-understanding-the-amazon-from-space
[^imagenet]: http://www.image-net.org/

The other driver of the recent success of image classification systems is the development of *Deep Learning* [@Lecun2015], a subfield of Machine Learning. Deep Learning or *Deep Neural Networks* (DNNs) is a class of models inspired by the structure and function of the brain called artificial neural networks. The type of DNN proven best suited for image classification problems are *Convolutional Neural Networks* (CNNs). CNNs is the uncontested state-of-the-art model for practically all image classification problems, mainly because of its ability of 'learning' highly discriminative feature representations of its input images. In the past, conventional approaches were built on carefully designed hand-crafted features such as SIFT [cite] and BoW [cite]. AlexNet [@Krizhevsky2012] was the first CNN to win ImageNet (in 2012) and thereafter, each of the following annual ImageNet competitions was won by a CNN.

The main focus of deep learning approaches for image classification, until recently, was on problems where each image is annotated with only a single label. *Multi-Label Classification* (MLC) [@Zhang2014] of images generalises this task to allow images to be annotated with more than one label. The majority of real-world images contain more than one object, making multi-label image classification a more general and practical problem, and naturally, also more challenging. Only recently more attention was given to multi-label image classification (for example, [@Wei2014]) and therefore the field is nowhere near the maturity level of its single-label counterpart. It is fair to assume that since DNNs are so powerful with single-label image classification, it may also be extended to successfully model images with multiple labels.

Extending CNNs and other DNNs to handle images with multiple labels is not a trivial task. Recently, a handful of proposals were made on how to tackle this task [cite them?]. However, these suggestions were mostly given in isolation of one another and no comprehensive review and comparison (theoretical or empirical) of these methods exist in the literature. Most of the proposals also come from a deep learning background and could gain from insights and methods already discovered in the field of MLC. 

In summary, the relevance of multi-label image classification, in terms of its wide range of useful practical applications, and the power of deep learning methods for image classification tasks, is the main motivation behind choosing this topic of research. This area of research is still relatively under explored and a comprehensive understanding and review of on the subject could lead to novel contributions to the literature. This is the secondary motivation behind the study. Exactly what this thesis aims to achieve will be discussed next.

## Objectives

The core of this study is to explore ways of applying DNNs to multi-label image classification problems. The direction of the research can be described by the following objectives. First, the intermediate objective of this study is to obtain a comprehensive understanding of the following research areas:

+ **The image classification problem** - This is the application domain for this study. A good understanding of the problem would lead to a solid foundation for further study in the domain. By disussing previous and basic approaches to the problem, the challenges and shortcomings in the domain can be identified.

+ **Deep neural networks and how they are applied to image classification** - This is the class of algorithms the study focusses on (more specifically, CNNs). Therefore, the understanding of DNNs is essential for further study on how they can be extended. The typical structures of DNNs for image classfication should be given attention to, in addition to how variations thereof influence the algorithms effectiveness in certain scenarios. Learning the limitations of the current networks would also be beneficial to the rest of the study.

+ **The multi-label classification framework** - This is the *supervised learning* paradigm in which this study will take place. Although only recently became popular, many contributions have been made to this field. Knowledge of the basic concepts, especially those novel relative to single label classification, the common challenges in the field and the state-of-the art algorithms would give valuable insights to the core of this thesis. The focus can mostly be agnostic to the application domain, however, previous work on multi-label image classifcation (other than DNNs), will also be insightfull.

> confused to how I must use could vs can and would vs will

The fulfillment of the above intermediate objective would be complementary to the main objective of learning how to effectively apply DNNs to a multi-label image classification probelm. This objective can be deconstructed into the following sub-objectives:

+ **Gather and review all the proposals on how to extend DNNs for multi-label image classification in the literature** - The literature on this subject is sparse, but there are enough proposals for a review on the subject to be relevant. The aim is to obtain a thorough understanding of each proposal, how it solves the multi-label classification problem and how effective it is in doing so. The conceptual differences between the approaches would be given considerable attention. If there are proposals for DNNs for MLC in other application domains, but the approach is transferable to image classification, these should also be considered. The various approaches should be discussed and compared under common notations.

+ **Suggest ways to improve existing approaches** - Learning from the strengths and weaknesses of each existing approach (from the review) would provide a good basis on to suggest improvements on existing approaches. These can either be extensions of existing approaches or novel approaches. The possibility of transferring ideas in pure MLC to deep learning to improve upon existing approaches would also be explored.

+ **Provide empirical evaluations and comparisons of the highlighted approaches** - The theory and discussions of the study can be complemented by empirical evaluations. Existing and suggested approaches can be evaluated on popular benchmark image datasets in order to compare them to each other and to compare them with the existing literature. This task will teach the implementations of such algorithms and highlight some of the challenges in doing so, not necessarily mentioned in the literature. 

When all these objectives are completed a master's level understanding on the topic of DNNs for multi-label image classification would have been obtained. Given a certain multi-label image classification problem, one would have the knowledge to reccommend some approaches above others, know its limitiation and have the ability to implement the approach.

> review these objectives as writing continues.

## Contributions

> rough - will complete after the contributions are actually done. This is roughly what I attempt to contribute.

Novel contributions made to the literature by this thesis:

+ First review of multi-label DNNs - there are a few papers on ML-CNN. They are usually compared to only a limited number of other approaches, on limited number of datasets and limited number of metrics. To the best of our knowledge, at the time of completing this thesis, no other work provides such an extensive review of the literature.

+ Some of the proposed algorithms empirical evaluations are lacking completeness. Usually they lack combinations of either or all of the following:

    + evaluated on multiple benchmark datasets
    + evaluated in terms of a representative set of multi-label evaluation metrics
    + estimated errors provided with standard errors
    + compared with a wide range of state-of-the-art algortihms

+ improvements on existing approaches?

## Code and Reproducibility

All of the code for this project, including the source docoments, is made available in the Thesis Github repository [^repo]. More instructions on how to implement the code is contained in the file named, `README.md`, in the repository.

> not sure about this section

[^repo]: https://github.com/jandremarais/Thesis

## Background and Important Concepts

In this thesis, the three key concepts of the study, *viz*. image classification, deep neural networks and multi-label classification, will be introduced in their own chapters (not sure yet if image classification should make up a whole chapter). Thereafter, a discussion of the combination of the above topics, in order to conceptualise image classification by means of DNNs for MLC, will follow.

Since we are interested in applying DNNs for MLC in the image classification domain, some background on image classification is first
required. Image classification is an example of a *superivised learning* task, hence in the remainder of this chapter, we start with a brief introduction to supervised learning followed by the general problem of image classification. Discussions of DNNs and of MLC follow in Chapters \ref{chp:dnn} and \ref{chp:mlc} respectively. A more comprehensive outline of the thesis may be found in \Cref{sec:outline}.

### Supervised Learning \label{sec:supervised}

Machine or statistical (used interchangably) learning algorithms are used to perform certain task that are too difficult to solve with fixed programs designed by humans. The algorithms are able to learn from data how to perform a task. For an algorithm to learn from data, means that it can improve its ability in performing the assigned task, with respect to some performance measure, by observing the data. This section gives a brief look at some the important types of tasks, data and performance measures in the field of statistical learning.

A learning task describes the way an algorithm should process an observation. An observation is a collection of features that have been quantitatively measured from some object or event that we want the system to process, like an image. We will represent an observation by a vector $\boldsymbol{x}\in\mathbb{R}^{p}$ where each element $x_{j}$ of the vector is an observed value of another feature. For example, the features of an image are usually the values of the pixels in the image.

Many kinds of tasks can be solved with statistical learning. One of the most common learning tasks is that of *classification*, where it is expected of an algorithm to determine which of $K$ categories an input belongs to. To solve this task, the learning algorithm is usually asked to produce a function $f:\mathbb{R}^{p}\to \{1,\dots,K\}$. When $y=f(\boldsymbol{x})$, the model assigns an input described by the vector $\boldsymbol{x}$ to a category identified by numeric code $y$. In other variants of the classification task, $f$ may output a probability distribution over the possible classes.

*Regression* is the other main learning task and requires the algorithm to predict a continuous value given some input. This task requires a function $f:\mathbb{R}^{p}\to\mathbb{R}$, where the only difference to classification is the format of its output.

Learning algorithms can learn to perform such tasks by observing a relevant set of data points, or dataset. A dataset containing $N$ observations of $p$ features is commonly described as a design matrix $X:N\times p$, where each row of the matrix represents a different observation and each column corresponding to a different feature of the observations. Often the dataset includes annotations for each observation in the form of a label (classification) or a target value (regression). The $N$ annotations are represented by the vector $\boldsymbol{y}$, where element $y_{i}$ is associated with the $i$-th row of $X$. Note, in the case of multiple labels or targets, a matrix representation $Y:N\times K$ is required.

Statistical learning algorithms can roughly be divided into two main categories, *supervised* and *unsupervised* algorithms, determined by the presence of annotations in the dataset to be analysed. Unsupervised learning algorithms learn from data consisting of only features, $X$, and are used to find useful properties and structure in the dataset [see @Hastie2009, Ch. 14]. On the other hand, superivised learning algorithms learn from datasets which consist of both features and annotations, $(X,Y)$, with the aim to model the relationship between them. Therefore, both classification and regression are considered supervised learning tasks.

In order to evaluate the ability of a learning algorithm to perform its assigned task, we must design a quantitative measure of its performance. For example, in a classification task we are usually interested in the accuracy of the algorithm, *i.e.* the percentage of times the algorithm makes the correct classification. Usually we are mostly interested in how well the learning algorithm performs on data that it has not seen before, since this demonstrates how it will work in real-world situations. Thus we evaluate the algorithm on a *test set* of data points, alternative to the *training set* of data points used in the learning process.

Consider the following example of a simple learning algorithm, known as *linear regression*, to give a more concrete understanding of supervised learning. The goal here is to build a system that can take a vector $\boldsymbol{x}\in \mathbb{R}^{p}$ as input and predict the value of a scalar $y\in \mathbb{R}$ as its output. In the case of linear regression we let the output be a linear function of the input. Let $\hat{y}$ be the value that our model predicts $y$ should take on. We define the output to be 

$$
\hat{y}=\hat{\boldsymbol{w}}^{T}\boldsymbol{x},
$$
where $\hat{\boldsymbol{w}}=[w_{0},w_{1},\dots,w_{p}]$ is a vector of paramaters and $\boldsymbol{x}=[1,x_{1},x_{2},\dots,x_{p}]$ to include the intercept in the model (also known as the *bias* in machine learning, not to be confused with bias in the statistical sence). The paramaters are values that control the behaviour of the system. We can think of them as a set of *weights* that determine how each feature affects the prediction. So the learning task can be defined as: to predict $y$ from from $\boldsymbol{x}$ by outputting $\hat{y}=\hat{\boldsymbol{w}}^{T}\boldsymbol{x}$. Note for now that the linear model is plays an important part in neural networks.

Next we need a defintion of a performance measure to evaluate the predictions made by the algorithm. A very common measure of performance in regression is the *mean squared error* of the model, given by:

$$
MSE = \frac{1}{N}\sum_{i=1}^{N}(y_{i}-\hat{y}_{i})^{2},
$$
evaluated on a set of $N$ observations. The process of learning from the data (or fitting the model to the data) is reduced to the optimisation problem of finding the set of weights $\hat{\boldsymbol{w}}$ that minimise MSE. This has a closed form solution and can quite trivially be found by means of *ordinary least squares* (OLS) [see @Hastie2009, p. 12]. However, we have mentioned that we are actually more interested in the algorithm's performance evaluated on a test set. Unfortanately, the least squares solution does not guarrantee the optimal solution in terms of the test MSE, making statisitical learning more than a pure optimisation problem.

The ability to perform well on previously unobserved inputs is called generalisation and is the central challenge of statistical learning. One way improving the generalisation ability of a linear regression model is by modifying the training criterion $J$, to include *weight decay*:

$$
J(\boldsymbol{w})=MSE_{\text{train}} +\lambda\boldsymbol{w}^{T}\boldsymbol{w}
$$
This criterion expresses preference for sets of weights with smaller values. $\lambda$ is a non-negative value chosen ahead of time controlling the strength of the preference by determining how much influence the penalty term $\boldsymbol{w}^{T}\boldsymbol{w}$ has on the optimisation criterion. If $\lambda=0$, no preference is imposed and the solution is equivalent to the OLS solution. Larger values of $\lambda$ forces the weights to become smaller, hence also known as a shrinkage method ([see @Hastie2009, pp. 61-79] for more such methods). This approach of modifying the learning algorithm to attempt to reduce its generalisation error but not its training error is known as *regularisation* [@Goodfellow2016, pp. 118-120].

We can further generalise linear regression to the classification scenario. First, note the different types of classification schemes. Consider $\mathcal{G}$, the discrete set of values which may be assumed by $G$, where $G$ is used here to denote a categorical output variable (instead of $Y$). Let $|\mathcal{G}|=K$ denote the number of discrete categories in the set $\mathcal{G}$. The simplest form of classification is known as binary classification and refers to scenarios where the input is associated with only 1 of possible 2 classes, *i.e.* $K=2$. When $K>2$, the task is known as multiclass classification. In multi-label classification an input may be associated with more than one of a possible $K$ classes, where the number of classes each observation belongs to is unknown. A thorough discussion of MLC methods are given in \Cref{chp:mlc}. Here, we will consider the single label cases of binary and multiclass classification.

In multiclass classification, given the input values $\boldsymbol{X}$, we would like to make good predictions of the output, $G$, which we denote as $\hat{G}$. One approach would be to denote $G$ as an indicator vector $\boldsymbol{Y}$, where its elements are all zero except at the $G$-th position where it is coded as a 1, *i.e.* $Y_{k}=1$ for $k=G$ and $Y_{k}=0$ for $k\neq G$. Then we can treat each of the elements in $\boldsymbol{Y}$ as quantitative outputs and predict values for it denoted by $\hat{\boldsymbol{Y}}=[\hat{Y}_{1},\dots,\hat{Y}_{K}]$. The class with the highest predicted value is then the final categorical output, *i.e.* $\hat{G}=\arg\max_{k\in\{1,\dots,K\}}\hat{Y}_{k}$.

Thus we seek a function of the inputs that can produce predictions of the class scores, *i.e.*

$$
\hat{Y}_{k}=\hat{f}_{k}(\boldsymbol{X}),
$$
for $k=1,\dots, K$, where $\hat{f}_{k}$ is an estimate of the true function, $f_{k}$ representing the relationship between the inputs and the outputs of class $k$. As with the linear regression case described above, we can use a linear model $\hat{f}_{k}(\boldsymbol{X})=\hat{\boldsymbol{w}}_{k}^{T}\boldsymbol{X}$ to approximate the true function. The linear model for classification divides the input space into a collection of regions labelled according to the classification, where the division is done by linear *decision boundaries* (see \autoref{fig:sgd} for an illustration). The decision boundary between classes $k$ and $l$ is the set of points for which $\hat{f}_{k}(\boldsymbol{x})=\hat{f}_{l}(\boldsymbol{x})$. These set of points form an affine set or hyperplane in the input space.

After the weights are estimated from the data, an observation represented by $\boldsymbol{x}$ (including the unit element) can be classified as follows:

+ compute $\hat{f}_{k}(\boldsymbol{x})=\hat{\boldsymbol{w}}_{k}^{T}\boldsymbol{x}$ for all $k=1,\dots,K$
+ identify the largest component and classify accordingly, *i.e.* $\hat{G}=\arg\max_{k\in\{1,\dots,K\}}\hat{f}_{k}(\boldsymbol{x})$

One may view the predicted class scores as estimates of the conditional class probabilities (or posterior probabilities), *i.e.* $P(G=k|\boldsymbol{X}=\boldsymbol{x})\approx \hat{f}_{k}(\boldsymbol{x})$. However, these values are not the best estimates of posterior probabilities. Although the values sum to 1, they do not lie within [0,1]. A way to overcome this problem is to estimate the posterior probabilities
using the logit transform of $\hat{f}_{k}(\boldsymbol{x})$. That is,

$$
P(G=k|\boldsymbol{X}=\boldsymbol{x})\approx\frac{e^{\hat{f}_{k}(\boldsymbol{x})}}{\sum_{l=1}e^{\hat{f}_{l}(\boldsymbol{x})}}.
$$
Through this transformation, the estimates of the posterior probabilities both sum to 1 and are squeezed into [0,1]. The above model is of course the
wellknown *logistic regression* model [@Hastie2009, p. 119]. With this formulation there are no closed form solution to the weights. Instead, the weight estimates may be searched for by maxmising log-likelihood. We can do this by minimising the negative log-likelihood using gradient descent, which will be discussed in the following section.

Finally, note that supervised learning problem problem can also be viewed as a function approximation problem. Suppose we are trying to predict a variable $Y$ given an input vector $\boldsymbol{X}$ where we assume the true relationship between them is given by:
$$
Y=f(\boldsymbol{X})+\epsilon,
$$
where $\epsilon$ stands for the part of $Y$ that is not predictable from $\boldsymbol{X}$, because of, for example, incomplete features or noise present in the labels. Then in function approximation we are estimating $f$ with an estimate $\hat{f}$. In some cases, like in the linear regression example, the estimation of $f(\boldsymbol{X},\theta)$ is equivalent to estimating the optimal set of weights, $\hat{\theta}$. For the remainder of the thesis, we refer to $\hat{f}$ as the *model*, *classifier* or *learner*.

### Optimisation \label{sec:optimisation}

Recall that the aim of training a model is to find the values of its internal parameters that minimise the so-called loss function, $L$. Therefore parameter estimation is an *optimisation* problem. Optimisation refers to the task of either minimising or maximising some function $R(x)$ by altering $x$. However, we usually phrase most optimisation problems in terms of minimisation. The function we want to minimise or maximise (optimise) is called the objective function. When we are minimising the objective function, we may also call it the cost function, loss function or error function. These terms we will use interchangeably throughout the remainder of the thesis.

As mentioned in the previous section, parameter estimation (or optimisation) of a linear (or logistic regression) model is usually done using OLS or MLE. In this section we however discuss an alternative parameter estimation method, since this method is typically also used to obtain estimates of neural network parameters.

Consider the popular loss function, *mean squared error* (MSE),

$$
\begin{aligned}
L&=\sum_{i=1}^{N}L_{i}\\
&=\sum_{i=1}^{N}\sum_{k=1}^{K}(y_{ik}-f_{k}(\boldsymbol{x}_{i}))^{2}\\
&=\sum_{i=1}^{N}\sum_{k=1}^{K}(y_{ik}-\boldsymbol{w}_{k}^{T}\boldsymbol{x}_{i})^{2},
\end{aligned}
$$
where $f_{k}(\cdot)$ in this case is the linear model used to predict the $k$-th class posterior probability. Although the MSE loss is mostly used in regression setups and not really well suited for classification, we make use of it here for illustration purposes.

To find the weights, $\boldsymbol{w}$, that minimise $L$, a possible approach is to follow a process of iterative refinement. That is, starting with a random initialisation of $\boldsymbol{w}$, one iteratively updates the values to decrease $L$. The updating steps are repeated untill the loss converges. In order to minimise $L$ with respect to $\boldsymbol{w}$ we calculate the gradient of the loss function at the point, $L(\boldsymbol{x};\boldsymbol{w})$. The gradient (or slope) of the loss function tells us the direction in which the function has the steepest rate of increase. Therefore, once we determined this direction, we can update the weights by a step in the opposite direction - thereby reaching a smaller value of $L$.

The gradient of $L_{i}$ is computed by taking the partial derivative of $L_{i}$ in terms of $\boldsymbol{\beta}$, *i.e.*:

$$
\frac{\partial L_{i}}{\partial\boldsymbol{w_{k}}}=-2(y_{ik}-\boldsymbol{w}_{k}^{T}\boldsymbol{x}_{i})\boldsymbol{x}_{i}
$$
Given the above derivatives, an update at the $(r+1)$-th iteration has the form

$$
\boldsymbol{w}_{k}^{(r+1)}=\boldsymbol{w}_{k}^{(r)}-\gamma\sum_{i=1}^{n}\frac{\partial L_{i}}{\partial\boldsymbol{w_{k}^{(r)}}},
$$
where $\gamma$ is called the *learning rate* and determines the size of the step taken into the optimal direction. One typically wants to set the learning rate small enough such that the minimum is not overshot, but enough to ensure not too many iterations before convergence. This value can be determined via a line search but is not always ideal since the training time of DNNs are too long. Another option is to reduce the learning rate after every fixed number of iterations, but more detail regarding the implication of the learning rate will be given in \autoref{chp:DNN}.

This procedure of repeatedly evaluating the gradient and then performing a parameter update is called *gradient descent* [Cauchy, 1847]. Although there are some ‘bells and whistles’ to add to this algorithm (later on discussed in \autoref{chp:dnn}), gradient descent is by far the most common and established way of optimising neural networks.

Notice that a weight update is made by evaluating the gradient over a set of observations, $\{\boldsymbol{x}_{i},i=1,\dots,n\}$. One of the advantages of gradient descent is that at an iteration, the gradient need not be computed over the complete training dataset, *i.e.* $n\le N$. When updates are iteratively determined by using subsets of the data, the process is called *mini-batch gradient descent*. This is extremely helpful in large-scale applications, since since it obviates computation of the full loss function over the entire dataset. This leads to faster convergence, because of more frequent parameter updates, and allows for the processing of large datasets that are too big to fit into a computer's memory. The choice in batch size depends on the available computation power, but typically a batch consists of 64, 128 or 256 data points, since in practice many vectorised operation implementations work faster when their inputs are sized in powers of 2. The gradient obtained using mini-batches is only an approximation of the gradient of the full loss but it seems to be sufficient in practice [@Li2014]. Note at this point that the collection of iterations needed to make one sweep through the training set is called an *epoch*.

The extreme case of mini-batch gradient descent is when the batch size is selected to be 1. This is called *Stochastic Gradient Descent* (SGD). Recently SGD has been used much less, since it is more efficient to calculate the gradient in larger batches compared to only using one example. However, note that it remains common to use the term SGD when actually referring to mini-batch gradient descent. Gradient descent in general has often been regarded as slow or unreliable but it works well for optimising DNNs. SGD will most probably not find even a local minimum of the objective function, it usually however find a very low value of the cost function quickly enoguh to be useful.

### Optimisation Example

To illustrate the SGD algorithm, consider the linear model in a classification context. Suppose we are given a training set with 2-dimensional inputs with only two possible classes. Let the data be generated in the same manner as described in [@Hastie2009, pp. 16-17]. We want to fit a linear regression model to the data such that we can classify an observation to the class with the highest predicted score. In the binary case it is only necessary to model one class probability and then assign an observation to that class if the score exceeds some threshold (usually 0.5), otherwise assign it to the other class. Therefore the decision boundary is given by $\{\boldsymbol{x}:\boldsymbol{x}^{T}\hat{\boldsymbol{w}}=0.5\}$.

The example is illustrated in \autoref{fig:sgd}. The colour shaded regions represent the parts of the input space classified to the respective classes determined by the decision boundary with the OLS paramter estimates. Gradient descent was applied to the determine the optimal weights using a learning rate of 0.001. Since the total number of training observations are small, it is not necessary to use SGD. In \autoref{fig:sgd} the dashed lines represent the decision boundary defined by the gradient descent paramater estimates at different iterations. We observe that initially the estimated decision boundary is far from the OLS solution, but as the update iterations are continued, the decision boundary is rotated and translated until finally matching the OLS line. It took 29 iterations for the procedure to reach convergence.

```{r, cache=TRUE, fig.cap = "Plots of gradient descent example. (a) The data points plot in the input space. The shade in the background represents the class division in the input space with the decision boundary determined by linear least squares estimation. The dashed lines represent the decision boundaries learned at different iterations. (b) The loss calculated at each iteration. \\label{fig:sgd}"}
# generate the data
set.seed(1)

K <- 2
m <- lapply(list(c(1, 0), c(0, 1), c(3, 3))[1:K], 
            function(a) mvrnorm(n = 10, mu = a, Sigma = diag(2)))

X <- lapply(m, function(b) {
  t(sapply(1:100, function(a) {
    mvrnorm(n = 1, mu = b[sample(10, 1), ], Sigma = diag(2)/5)
  }))
})

D <- data.frame(X = do.call("rbind", X), Y = rep(0:(K-1), each = 100))
D <- cbind(X.0 = 1, D)
#D[, -3] <- scale(D[, -3])

# SGD
lin_model <- function(x, b) sum(x * b)
L <- function(y, yhat) sum((y - yhat)^2)

set.seed(125)
B <- mvrnorm(1, mu = c(0, 0, 0), Sigma = diag(3))
B_mat <- B
yhat <- apply(D[, -3], 1, function(a) lin_model(a, B))
loss <- L(D$Y, yhat)
lr <- 0.001
for(i in 1:200) {
  gradient <- c(-2*t(as.matrix(D[, -4])) %*% (D$Y - yhat))
  B_new <- B - lr * gradient
  
  yhat <- apply(D[, -4], 1, function(a) lin_model(a, B_new))
  loss <- c(loss, L(D$Y, yhat))
  
  if(abs(loss[i+1] - loss[i]) < 0.00001) {
    return()
  } else {
    B <- B_new
    B_mat <- rbind(B_mat, B_new)
  }
  #B <- B_new
}

x <- as.matrix(D[, -4])
Bhat <- solve(t(x)%*%x)%*%t(x)%*%D$Y

d_bounds <- t(apply(B_mat, 1, function(a) c(slope = -a[2]/a[3], intercept = (0.5-a[1])/a[3])))
rownames(d_bounds) <- NULL
d_bounds <- data.frame(iteration = 0:(nrow(d_bounds)-1), d_bounds)
d_bounds <- d_bounds[c(1, 5, 10, 30), ]

xlims <- range(D$X.1) * 1.1
ylims <- range(D$X.2) * 1.1

shade_x <- seq(xlims[1], xlims[2], len = 100)
shade_y <- -shade_x*Bhat[2]/Bhat[3] + (0.5 - Bhat[1])/Bhat[3]
shade_y[shade_y>ylims[2]] <- ylims[2]

db_coords <- t(sapply(1:nrow(d_bounds), function(a) {
  ycut <- xlims[2] * d_bounds[a, "slope"] + d_bounds[a, "intercept"]
  if(ycut < ylims[2]) {
    c(xlims[2], ycut)
  } else {
    c((ylims[2] - d_bounds[a, "intercept"])/ d_bounds[a, "slope"], ylims[2])
  }
}))
colnames(db_coords) <- c("dx", "dy")
d_bounds <- cbind(d_bounds, db_coords)

library(latex2exp)
# Plot
p <- D %>% 
  ggplot() + 
  geom_point(aes(X.1, X.2, color = factor(Y)), show.legend = FALSE)+
  #coord_fixed() +
  theme(panel.background = element_rect(fill = "white")) +
  geom_abline(data = d_bounds, aes(slope = slope, intercept = intercept), linetype = "dashed") +
  geom_ribbon(data = data.frame(shade_x, shade_y),
            aes(x = shade_x, ymin = ylims[1], ymax = shade_y), alpha = 0.15, fill = "red") +
  geom_ribbon(data = data.frame(shade_x, shade_y),
            aes(x = shade_x, ymin = shade_y, ymax = ylims[2]), alpha = 0.15, fill = "blue") +
  scale_y_continuous(expand = c(0, 0), name = TeX("$X_2$"), breaks = NULL) + 
  scale_x_continuous(expand = c(0, 0), name = TeX("$X_1$"), breaks = NULL) +
  geom_text(data = d_bounds, aes(dx, dy, label = paste0("i=", iteration)), hjust = c(1, rep(0, 3)), 
            vjust = c(0, rep(1, 3)), nudge_y = c(0, rep(-0.02, 3)), nudge_x = c(-0.02, rep(0, 3))) +
  panel_border(colour = "black")

loss_data <- data.frame(loss = loss, iteration = 0:(length(loss) - 1)) 
library(ggthemes)
p_loss <- loss_data %>% 
  ggplot(aes(iteration, loss)) + 
  geom_line(color = "blue") +
  theme(axis.ticks.y = element_blank()) +
  # theme(panel.background = element_rect(fill = "white"),
  #       axis.ticks.x = element_blank()) +
  geom_segment(data = loss_data[c(1,5,10,30), ], aes(x = iteration, xend = iteration, yend = 0), linetype = "dashed") +
  scale_y_continuous(expand = c(0, 0), labels = NULL) + 
  scale_x_continuous(expand = c(0.05, 0), breaks = c(0, 4, 9, 29))

plot_grid(p, p_loss, labels = c("(a)", "(b)"), nrow = 1, align = "vh", rel_widths = c(3,2))
```

Deep learning is a specific kind of statistical learning, therefore a broad recipe for deep learning algorithms can be given as the combination of a dataset, a cost function, optimisation procedure and a model. We have discussed all of these ingredients in simple and general terms, and are now ready to narrow the focus to deep learning methods. The next section on image classification introduces the type of datasets relevant to the application of this thesis.

### Image Classification

+ see also [Object recognition from local scale-invariant features] for sliding window approach.

Conventional image classification is the task of assigning one label from a fixed set of categories to an input image. This is an important task in Computer Vision with many applications already mentioned in \Cref{sec:moti}. A rather neglected topic in the literature, and the focus of this thesis, is that of assigning potentially more than one label to an input image, known as multi-label image classification. However, before we move on to the multi-label case, we must obtain a thorough understadning of single label image classification.

A generic approach for building a standard image classifer is as follows. First, one needs to collect a large set of labelled images, relevant to the application. The image classifier is supposed to take a raw image as input and produce a vector of class scores as output. The class scores represent the classifier's confidence for each class's presence in the input image. We want the classifier to assign the highest class score to the actual class of the image. Without any training of the classifier, this is not likely to happen. The amount by which the predicted class scores deviate from the ground truth can be measured by an objective function (also called a loss function). 

Now the *training* of the classifier can commence, and it works as follows. The classifier is iteratively shown images in the training dataset. For each image it computes its class scores and then evaluates the accuracy of these scores in terms of the loss function. Then the classifier can adjust its internal parameters in an attempt to improve its accuracy. These steps can be repeated until a satisfactory loss value has been reached. This task of training a model to learn from labelled data is known as *Supervised Learning*.

### Conventional Methods to Image Classification

Now that we understand the principles of supervised learning, let us look at the nature of the inputs and outputs of a typical image classification problem. An image is a grid of many tiny, square cells of different colors. These cells are known as pixels and one pixel represents one color. A grayscale image, 32 pixels wide and 32 pixels long, can be represented by a $32\times 32$ matrix of integers, where each integer represents the 'brightness' (intensity) of each pixel. These integers are usually in $[0,255]$, such that the greater the integer the brighter the pixel, *i.e.* a pixel with intensity 0 is totally black and a pixel with intensity 255 is totally white. \autoref{fig:img_mat} illustrates this representation. Note, that a standard color image consists of 3 spectral bands, red, green and blue (RGB), *i.e.* the color of one pixel is determined by 3 integers in $[0,255]$, each representing the intensity of the color red, green and blue, respectively. Thus a $32\times32$ sized image is represented by an array of size $32\times32\times3$.

```{r,fig.cap="A low resolution grayscale profile of a man with pixel values overlayed on the image.\\label{fig:img_mat}", cache=TRUE, fig.width=3, fig.height=3}
load.image("figures/wim.jpeg") %>% 
  grayscale %>% 
  resize(16, 16) %>% 
  as.data.frame %>% 
  ggplot(aes(x, y)) + 
  geom_raster(aes(fill = value), show.legend = FALSE) +
  scale_y_continuous(trans=scales::reverse_trans(), expand = c(0, 0)) +
  scale_x_continuous(expand = c(0, 0)) + 
  scale_fill_gradient(low = "black", high = "white") +
  coord_fixed() +
  theme(text = element_blank(), line = element_blank()) +
  geom_text(aes(label = round(value * 256), color = value), show.legend = FALSE, size = 2) +
  scale_color_gradient(low = "white", high = "black")
```



Before moving on, it is worth noting some of the things that make it hard for computers to classify images [^challenges]:

+ **Viewpoint variation** - A single instance of an object can be oriented in various ways with respect to the camera position.
+ **Scale variation** - Objects of the same class can appear in different sizes in the images.
+ **Deformation** - 
+ **Occlusion**
+ **Illumination conditions**
+ **Background clutter**
+ **Intra-class variation**

> incomplete since I'm not sure if I want to add this list. Thus far it is basically a copy of the one found in the reference. Think the challenges should be mentioned but this section is getting very long.

> maybe mention that pure classification of objects in an image seem limited and that we might want to localise the objects in terms of bounding boxes or segmentation. This is somewhat true. However, ML-CNNs can provide a rough localisation with attention maps. Also, annotation of bounding boxes and segmentation maps are expensive to obtain.

[^challenges]: http://cs231n.github.io/classification/ unsure how to cite websites.

Singel-label image classification is the task of assigning a label from a predefined set to an image. It is already practically considered a solved problem, mostly owed to large-scale labelled image datasets, such as ImageNet [@Deng2009], and the recent developments in Deep Convolutional Neural Networks (DCNNs) [@Krizhevsky2012]. Although the main work of this thesis is on deep learning methods for multi-label image classification, a brief overview of conventional (non-deep learning) methods for single-label image classification, will promote a deeper understanding of the image classification problem in general and will most likely lead to a better appreciation of the power and effectiveness of deep learning methods.

Before the success of deep learning, the state-of-the-art image classification models were Bag-of-Words (BoW) based models. BoW based models can roughly be decomposed into the following modules: 

+ Feature Representation,
+ Classification and
+ Context Modelling.

Conventional Statistical Learning methods struggle to process data in its natural or raw form, *e.g.* images as raw pixel intensities. An effective image classifier is insensitive to irrelevant variations of the input, such as the position, orientation or illumination of an object, while being very sensitive to other particular details such as the facial attributes of an animal when distinguishing a cat from a dog, for example. Even the state-of-the-art classifiers, such as Random Forests, Support Vector Machines and Boosting find it extremely difficult to discriminate between the relevant and irrelevant aspects of an image from only raw pixel data. There are some obvious reasons for this. Firstly, the conventional classifiers require each observation to be represented by a vector and therefore the raw pixel data of each image is first flattend into a vector before it is given as input to the classifier. This approach discards most of the shape information in the image. In addition, these flattened vectors are very high-dimensional ($256\times 256 \times 3 = 196608$ for a colour image of size $256\times 256$), subjecting the classifier to the well-known problem in Statistical Learning, the *curse of dimensionality* [@Hastie2009].

To compensate for this shortcoming of conventional classifiers, plenty of attention was given to the design of feature representations of images. Using these feature representations as input to a conventional classifier (instead of raw pixel data) makes it considerably easier for a classifier to recognise the input-output relationships. Building these feature representations are quite complex. Generally, building a feature representation will consist of some or all all of the following steps. First, hand-engineerd (local) features, such as Scale Invariant Feature Transform (SIFT) [@Lowe2004] and Histogram of Oriented Gradients (HOG) [@Dalal2005], are extracted from dense grids or via sparse interest point detection in the images. Feature encoding. Feature pooling. This results in a feature representation of an image that is much easier for conventional classifiers to learn from than raw pixel data.

> Still need to explain (but its complicated):

+ feature coding (quantize of points of interest): Vector quantization (Image coding using vector quantization: A review), Sparse coding (Sparse representation for computer vision and pattern recognition,  Locality-constrained linear coding for image classification, Linear spatial pyramid matching uisng sparse coding for image classification) and Gaussian Mixture models (Vector quantization based on gaussian mixture models)
+ and feature pooling (aggregation of features): SPatial pyramid matching (Beyond bags of features: Spatial pyramid matching for recognizing natural scene categories) looks like this also utilises spatial context
+ dont know yet where fisher vectors (Fisher kernels on visual vocabularies for image categorization) and VLAD (Aggregating local descriptors into a compact image representation) fit in. Think under pooling

> i am considering elaborating on these methods, to make this a chapter that can replace the previous image classification chapter.
    
Examples of commonly used classifiers on-top of the above mentioned feature representations are Random Forests [@Breiman2001] and Support Vector Machines (SVMs) (as used in [@Sanchez2011], for example). However, these classifiers can be further improved upon by making use of contextual information such as the spatial location of an object [@Harzallah2009].

As mentioned before, this approach to image classification is not trivial, with many complex facets to the modelling process. It usually requires considerable engineering skill and/or domain expertise, especially to create feature representations of images. In addition, these feature representations are only suited for a subset of image classification tasks and do not generalise well. This is where deep learning methods prove to be superior, since it has the ability to learn these feature representations from the data.






## Outline \label{sec:outline}

From this point on the reader should have a basic understanding of the topic of this thesis. The reasons why this topic was chosen has been described in the Motivations section and the goals of completing this thesis under the Objectives section. How this thesis will contribute to the literature has also been given. The problem of image classification has been introduced with the help of basic examples, along with a brief conceptual description of the multi-label image classification problem. Therefore, the reader should also be comfortable with the problem we want the DNNs to solve and the common challenges to such a problem. Although, DNNs have not yet been introduced, it should have been sufficient to know that it is class of algorithms. However, brief glimpses of the main components of DNNs have been given under the image classification problem description.

The rest of the thesis will follow the following outline. Chapter \ref{chp:dnn} introduces deep neural networks for image classifcation. Convolutional neural networks are specifically good at image classification and therefore most of the chapter will deal with them. The main focus is on the different structures and layers of the networks and how these influence performance (review this sentence - probably need to elaborate). 

Chapter \ref{chp:mlc} starts with the fundamentals of multi-label classification. It includes a formal definition and emphasis on the important concepts, such as multi-label evaluation metrics and the modelling of label dependencies (maybe add class imbalance here). The chapter also includes a review of the state-of-the-art algorithms for MLC. A discussion is given on the challenges and ongoing research of the field. One of the objectives of this chapter is to find approaches that could help extend DNNs for multi-label image classification. 

Chapter \ref{chp:dnn_mlc} reviews deep learning approaches for multi-label image classification. It looks at practically all of the proposals in the latest literature, how they attempt to model multiple labels and what are their shortcomings. The extensions are mostly adaptions of loss functions to be optimised or structural changes of the networks. An extensive comparision of the approaches is an important part of the chapter. Should I make proposals in this chapter?

Chapter \ref{chp:results} evaluates the highlighted approaches in previous chapter on popular benchmark image datasets. Note that more on the benchmark datasets are given in Appendix \ref{app:data}. The goal is to give a comprehensive empirical comparison of the best representative approaches in terms of many multi-label evaluation metrics (with standard errors). It includes discussions on the challenges of implementing these approaches and how the results correlate with the literature. The experiments done in this chapter are made as reproducible as possible with additional information on the code and software given in Appendix \ref{app:code}.

The thesis is concluded in Chapter \ref{chp:conc} with a summary of the work done in this project, general discussion of the literature and results and what directions can be followed for future research. It includes a section on the limitations of this study.