---
output: pdf_document
---

# Neural Networks \label{ch:nn}

## Introduction

# Convolutional Neural Networks

## Introduction

## Core Layers

### Convolutional Layers

### Pooling Layers

### Activation Layers

### Fully Connected Layers

### Learning Rates

+ cyclical
+ decay
+ momentum

### Freezing Layers

+ https://arxiv.org/abs/1706.04983

## Summary

# Convolutional Neural Networks in Practice (other title)

## Introduction

## Visualizing CNN's

## Transfer Learning

+ ImageNet

## Famous Architectures

+ AlexNet, Inception, ...

### VGG

### ResNet

### DenseNet

## Regularization

### Normalization Layers (maybe move to core)

### Data Augmentaion

### Pseudo-Labelling and Knowledge-Distillation

### Dropout

## Generalization (?)

+ https://arxiv.org/abs/1706.01350

# Multi-Label Convolutional Neural Networks

## General Multi-Label Learning Approaches

## Spatial Regularization Networks

+ https://arxiv.org/pdf/1702.05891.pdf

## From Single to Multi Output Paper ()

## RNN-CNN paper ()

+ Other object detection

# Things that need a place:

+ challenges for image classification: (maybe in CNNs in practive)

    + http://cs231n.github.io/classification/

+ Feature learning
+ one-shot learning:

    + https://github.com/sorenbouma/keras-oneshot
    + https://github.com/fchollet/keras/blob/master/examples/mnist_siamese_graph.py
    + https://sorenbouma.github.io/blog/oneshot/
    
+ multi-task learning:

    + https://arxiv.org/abs/1706.05137
    
+ test time augmentation
+ relational learning: 

    + https://arxiv.org/pdf/1706.01427.pdf

+ Fully-Convolutional Networks
+ Spatial Pyramid Pooling: https://github.com/yhenon/keras-spp
+ AutoML:

    + https://research.googleblog.com/2017/05/using-machine-learning-to-explore.html

